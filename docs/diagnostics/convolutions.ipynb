{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translations and Convolutions\n",
    "\n",
    "In preparation for the use of autograd to calculate the derivatives in scarlet, this is a test of using FFT's in pytorch to perform fractional translations and the errors and biases that they introduce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.ndimage.filters as spif\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    use_torch = True\n",
    "    import scarlet.torch\n",
    "except ImportError:\n",
    "    use_torch = False\n",
    "\n",
    "import scarlet\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "matplotlib.rc('image', cmap='inferno')\n",
    "matplotlib.rc('image', interpolation='none')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing FFT convolution with images\n",
    "\n",
    "We first test a point source convolved with a Gaussian PSF to test how using FFT's in numpy and pytorch compare to true convolution in scipy in terms of accuracy and runtime.\n",
    "\n",
    "First we generate our PSF and deconvolved image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gauss2d(x, y, A=1, x0=0, y0=0, sigma_x=2, sigma_y=2):\n",
    "    # Return a 2D circular Gaussian\n",
    "    return A * np.exp(-(0.5*(x-x0)**2/sigma_x**2+0.5*(y-y0)**2/sigma_y**2))\n",
    "\n",
    "def create_psf(radius):\n",
    "    # Create a PSF with a given radius\n",
    "    x = np.linspace(-radius, radius, 2*radius + 1)\n",
    "    y = np.linspace(-radius, radius, 2*radius + 1)\n",
    "    # Notice that in pytorch meshgrid is in reverse form of numpy\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    return gauss2d(X, Y)\n",
    "\n",
    "def project_image(img, shape):\n",
    "    # Project an image centered in a larger image\n",
    "    # We'll need this later, so we might as well define it now\n",
    "    result = np.zeros(shape)\n",
    "    N, M = shape\n",
    "    cy = N // 2\n",
    "    cx = M // 2\n",
    "    icy = img.shape[0] // 2\n",
    "    icx = img.shape[1] // 2\n",
    "    yslice = slice(cy-icy, cy+icy+1)\n",
    "    xslice = slice(cx-icx, cx+icx+1)\n",
    "    result[yslice, xslice] = img\n",
    "    return result\n",
    "\n",
    "psf_radius = 10\n",
    "cx = cy = 10\n",
    "N = 2*cx + 1\n",
    "\n",
    "psf = create_psf(psf_radius)\n",
    "plt.imshow(psf)\n",
    "plt.title(\"PSF\")\n",
    "plt.show()\n",
    "deconvolved = np.zeros((N, N))\n",
    "deconvolved[cy, cx] = 1\n",
    "plt.imshow(deconvolved)\n",
    "plt.title(\"deconvolved image\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we test the accuracy of the three different algorithms. Below is the code for numpy, while the pytorch implementation is coded into scarlet with the necessary modifications to work on `Tensors` as opposed to numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the true convolution using scipy\n",
    "scipy_img = spif.convolve(deconvolved, psf)\n",
    "# Perform FFT convolution using numpy and scarlet/pytorch\n",
    "np_img = scarlet.fft_convolve(deconvolved, psf)\n",
    "\n",
    "plt.imshow(scipy_img)\n",
    "plt.title(\"truth\")\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "residual = scipy_img-np_img\n",
    "max_residual = np.max(np.abs(residual))\n",
    "plt.imshow(residual, vmin=-max_residual, vmax=max_residual, cmap=\"seismic\")\n",
    "plt.title(\"numpy FFT residual\")\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "if use_torch:\n",
    "    torch_deconvolved = torch.tensor(deconvolved)\n",
    "    torch_psf = torch.tensor(psf)\n",
    "    torch_img = scarlet.torch.filters.fft_convolve(torch_deconvolved, torch_psf)\n",
    "\n",
    "    residual = scipy_img-np.array(torch_img)\n",
    "    max_residual = np.max(np.abs(residual))\n",
    "    plt.imshow(residual, vmin=-max_residual, vmax=max_residual, cmap=\"seismic\")\n",
    "    plt.title(\"pytorch FFT residual\")\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we test all three algorithms for speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_sizes = np.array([10, 20, 30, 40, 50])\n",
    "times = np.zeros((3, len(img_sizes)))\n",
    "time_stdev = np.zeros((3, len(img_sizes)))\n",
    "\n",
    "# scipy\n",
    "for n, img_size in enumerate(img_sizes):\n",
    "    cx = cy = img_size\n",
    "    N = 2*cx + 1\n",
    "    \n",
    "    psf = project_image(create_psf(psf_radius), (N, N))\n",
    "    deconvolved = np.zeros((N, N))\n",
    "    deconvolved[cy, cx] = 1\n",
    "    \n",
    "    result = %timeit -o -q -n 10 spif.convolve(deconvolved, psf)\n",
    "    times[0, n] = result.average\n",
    "    time_stdev[0, n] = result.stdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy\n",
    "for n, img_size in enumerate(img_sizes):\n",
    "    cx = cy = img_size\n",
    "    N = 2*cx + 1\n",
    "    \n",
    "    psf = project_image(create_psf(psf_radius), (N, N))\n",
    "    deconvolved = np.zeros((N, N))\n",
    "    deconvolved[cy, cx] = 1\n",
    "    \n",
    "    # numpy\n",
    "    result = %timeit -o -q -n 100 scarlet.fft_convolve(deconvolved, psf)\n",
    "    times[1, n] = result.average\n",
    "    time_stdev[1, n] = result.stdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch\n",
    "if use_torch:\n",
    "    for n, img_size in enumerate(img_sizes):\n",
    "        cx = cy = img_size\n",
    "        N = 2*cx + 1\n",
    "\n",
    "        psf = project_image(create_psf(psf_radius), (N, N))\n",
    "        deconvolved = np.zeros((N, N))\n",
    "        deconvolved[cy, cx] = 1\n",
    "    \n",
    "        torch_psf = torch.tensor(psf)\n",
    "        torch_deconvolved = torch.tensor(deconvolved)\n",
    "        # pytorch\n",
    "        result = %timeit -o -q -n 100 scarlet.torch.filters.fft_convolve(torch_deconvolved, torch_psf)\n",
    "        times[2, n] = result.average\n",
    "        time_stdev[2, n] = result.stdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = img_sizes*2 + 1\n",
    "plt.errorbar(x, times[0], time_stdev[0], label=\"scipy\")\n",
    "plt.errorbar(x, times[1], time_stdev[1], label=\"numpy\")\n",
    "if use_torch:\n",
    "    plt.errorbar(x, times[2], time_stdev[2], label=\"pytorch\")\n",
    "plt.xlabel(\"image pixels\")\n",
    "plt.ylabel(\"time (s)\")\n",
    "plt.yscale(\"log\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "if use_torch:\n",
    "    result_str = \"For {0} pixels: scipy = {1:.2f} ms, numpy = {2:.3f} ms, pytorch = {3:.3f} ms\"\n",
    "else:\n",
    "    result_str = \"For {0} pixels: scipy = {1:.2f} ms, numpy = {2:.3f} ms\"\n",
    "print(result_str.format(x[0], 1000*times[0,0], 1000*times[1,0], 1000*times[2,0]))\n",
    "print(result_str.format(x[-1], 1000*times[0,-1], 1000*times[1,-1], 1000*times[2,-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we see that FFT convolution is significantly faster than true convlutions, even for images this small, and the effect grows exponentially with image size.\n",
    "\n",
    "The main speed difference between numpy and pytorch is that pytorch has much slower indexing. This means that `sinc` is *much* slower in pytorch, so we use numpy to calcualte the Lanczos kernel and then convert the result to a pytorch `Tensor`. There is an open [ticket](https://github.com/pytorch/pytorch/issues/5388) out in pytorch to fix this, but until that happens we will probably see slower than expected runtimes with pytorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling the pixel grid\n",
    "\n",
    "Recall that in scarlet all of the sources are modeled such that they are in the center of a bounding box that is reprojected into the blended scence, usually at some fractional pixel location. The Whittaker-Shannon Sampling Theorem tells us that we can perfectly reconstruct a continuous signal from a set of well-sampled ($\\Omega$-bandlimited) discrete measurements with the formula\n",
    "\n",
    "$$f(t) = \\sum_{k=-\\infty}^{k=\\infty} f\\left(\\frac{k \\pi}{\\Omega}\\right) \\textrm{sinc}\\left(\\frac{\\Omega t}{\\pi} -k \\right)$$\n",
    "\n",
    "where $F(\\omega)$, the fourier transform of $f$, is piecewise continuous on $[-\\Omega, \\Omega]$, $t\\in\\mathcal{R}$, and the samples are obtained at the points $t_k=k/\\pi$. Unfortunately this function is not practically useful, as sinc falls off slowly and technically requires an infinite number of samples to prefectly reconstruct the signal.\n",
    "\n",
    "Practically we must use some windowed function that approximates sinc with just a few dozen samples.\n",
    "\n",
    "### Cubic Splines\n",
    "\n",
    "The most common technique in computer graphics for resampling is the cubic spline, due to its speed an accuracy at approximating the sinc. Splines are windows on a sinc function of the form\n",
    "\n",
    "$$ w(x, a, b) = \\frac{1}{6}\\cdot\n",
    "\\begin{cases}\n",
    "(-6a-9b+12)\\cdot |x|^3 + (6a+12b-18)\\cdot |x|^2 -2b + 6 & 0\\leq |x| \\leq1 \\\\\n",
    "(-6a-b)\\cdot |x|^2 + (30a + 6b)\\cdot |x|^2 -(48a + 12b)|x|+24a + 8b & 1 \\leq |x| \\leq 2 \\\\\n",
    "0 & \\textrm{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "where $a$ and $b$ are parameters that determine the sharpness and shape of the spines respectively. Two of the most common splines used in computer graphics are the Catmull-Rom spline ($a=0.5$, $b=0$) and the Mitchel-Netravali spline ($a=b=1/3$).\n",
    "\n",
    "### Lanczos \n",
    "\n",
    "It is generally accepted that a better approximation to the sinc is a Lanczos kernel\n",
    "\n",
    "$$L(x) =\n",
    "\\begin{cases}\n",
    "\\textrm{sinc}(x)\\cdot \\textrm{sinc}\\left(x/a \\right) & -a \\leq x \\leq a \\\\\n",
    "0 & \\textrm{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "is a better approximation to the sinc but often computationally more expensive due to its use of trig functions. \n",
    "\n",
    "### Testing resampling algorithms\n",
    "\n",
    "Understanding the limitations of these interpolations and any biases that they introduce is important for our evaluation of scarlet.\n",
    "\n",
    "We first test the accuracy of the three methods as well as linear interpolation of the nearest neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def test_resampling_algorithm(x0, y0, radius=10, moment=1, **kwargs):\n",
    "    \"\"\"For a given x and y offset, calculate the true gaussian\n",
    "    and resampled gaussian at a fractional position and return\n",
    "    the given moment.\n",
    "    \"\"\" \n",
    "    x = np.linspace(-radius, radius, 2*radius + 1)\n",
    "    y = np.linspace(-radius, radius, 2*radius + 1)\n",
    "\n",
    "    X,Y = np.meshgrid(x, y)\n",
    "    centered = gauss2d(X, Y, x0=0, y0=0)\n",
    "    truth = gauss2d(X, Y, x0=x0, y0=y0)\n",
    "    if use_torch:\n",
    "        interpolated = scarlet.filters.fft_resample(torch.tensor(centered), x0, y0, **kwargs)\n",
    "    else:\n",
    "        interpolated = scarlet.filters.fft_resample(centered, x0, y0, **kwargs)\n",
    "    return (truth-interpolated)**moment\n",
    "\n",
    "def ordinal(x):\n",
    "    \"\"\"Return the correct ordinal for a number\n",
    "    \"\"\"\n",
    "    _x = x % 10\n",
    "    if _x == 1:\n",
    "        return \"st\"\n",
    "    if _x == 2:\n",
    "        return \"nd\"\n",
    "    if _x == 3:\n",
    "        return \"rd\"\n",
    "    return \"th\"\n",
    "\n",
    "def test_resampling(moment, algorithm, radius=10, **kwargs):\n",
    "    \"\"\"Test the accuracy of an interpolation algorithm\n",
    "    \n",
    "    Iterate through a range of dx and dy values to calculate the moments of the interpolated residuals\n",
    "    \"\"\"\n",
    "    kernel = kernels[algorithm]\n",
    "    xs = np.linspace(0,.5, 6)\n",
    "    N = len(xs)\n",
    "    moments = np.zeros((N, N, 2*radius+1, 2*radius+1))\n",
    "\n",
    "    # First calculate the 1st and 2nd moment\n",
    "    for i in range(N):\n",
    "        dy = xs[i]\n",
    "        for j in range(N):\n",
    "            dx = xs[j]\n",
    "            moments[i, j] = test_resampling_algorithm(dx, dy, moment=moment, kernel=kernel, **kwargs)\n",
    "\n",
    "    # Set the same color mapping for all of the plots of the same moment\n",
    "    vmax = np.max(np.abs(moments))\n",
    "    if moment % 2:\n",
    "        vmin = -vmax\n",
    "        cmap = \"seismic\"\n",
    "    else:\n",
    "        vmin = 0\n",
    "        cmap = \"inferno\"\n",
    "\n",
    "    # Generate a plot for each dx,dy combination, for the 1st and 2nd moments\n",
    "    fig, axes = plt.subplots(nrows=N, ncols=N, figsize=(15, 13), gridspec_kw={\"hspace\":0, \"wspace\": .1})\n",
    "    for i in range(N):\n",
    "        dy = xs[i]\n",
    "        for j in range(N):\n",
    "            dx = xs[j]\n",
    "            ax = axes[i][j]\n",
    "            _moment = moments[i, j]\n",
    "            im = ax.imshow(_moment, vmin=vmin, vmax=vmax, cmap=cmap)\n",
    "            ax.get_xaxis().set_visible(False)\n",
    "            ax.get_yaxis().set_ticks([])\n",
    "            if i == 0:\n",
    "                ax.set_title(\"dx={0:.1f}\".format(dx))\n",
    "            if j == 0:\n",
    "                ax.set_ylabel(\"dy={0:.1f}\".format(dy))\n",
    "    cbar = fig.colorbar(im, ax=axes.ravel().tolist(), pad=.02)\n",
    "    cbar.set_label(\"{0}{1} moment\".format(moment, ordinal(moment)))\n",
    "    fig.suptitle(\"Algorithm: {0}\".format(algorithm), y=.92)\n",
    "    plt.show()\n",
    "\n",
    "if use_torch:\n",
    "    kernels = {\n",
    "        \"lanczos\": scarlet.torch.filters.lanczos,\n",
    "        \"catmull_rom\": scarlet.torch.filters.catmull_rom,\n",
    "        \"mitchel_netravali\": scarlet.torch.filters.mitchel_netravali,\n",
    "        \"bilinear\": scarlet.torch.filters.bilinear_interpolation,\n",
    "    }\n",
    "else:\n",
    "    kernels = {\n",
    "        \"lanczos\": scarlet.filters.lanczos,\n",
    "        \"catmull_rom\": scarlet.filters.catmull_rom,\n",
    "        \"mitchel_netravali\": scarlet.filters.mitchel_netravali,\n",
    "        \"bilinear\": scarlet.filters.bilinear_interpolation,\n",
    "    }\n",
    "\n",
    "for kernel in kernels:\n",
    "    test_resampling(1, kernel)\n",
    "\n",
    "\n",
    "for kernel in kernels:\n",
    "    test_resampling(2, kernel)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the Catmull-Rom and Lanczos kernels have 1st moments that are qualitatively different but similar in magnitude, and more accurate than the Mitchel-Netravali spline, however the Lanczos slightly outperforms both of them in the second moment. Unsurprisingly the linear interpolation is the least accurate of the four in both moments.\n",
    "\n",
    "When we calcualte the runtime of each algorithm we get a surprise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = create_psf(10)\n",
    "\n",
    "for kernel in kernels:\n",
    "    print(kernel)\n",
    "    if use_torch:\n",
    "        %timeit scarlet.torch.filters.fft_resample(torch.tensor(img), .1, .4, kernels[kernel])\n",
    "    else:\n",
    "        %timeit scarlet.filters.fft_resample(img, .1, .4, kernels[kernel])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently the implementation of piecewise functions in python is slower than using trig functions, so in this implementation the Lanczos kernel is not only the most accurate, but the fastest as well."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
