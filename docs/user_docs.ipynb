{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Guide"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. note::\n",
    "\n",
    "    `astropy`_, `matplotlib`_, and execution of the following initialization cell\n",
    "    are required to execute some of the code on this page.\n",
    "\n",
    ".. _matplotlib: https://matplotlib.org\n",
    ".. _astropy: http://www.astropy.org"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. warning::\n",
    "\n",
    "    There will be API changes in the future to optimize the code and enable additional features. Nonetheless, the code is fully functional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "The purpose of this guide is to explain the basic concepts of the *scarlet* package and how they are used. We also show how they can be extended and customized for more specialized science cases.\n",
    "The [API Documentation](api_docs.rst) contains more detailed descriptions of the modules and classes used in *scarlet*, and a more rigorous overview of the mathematics and algorithms used by *scarlet* is described in [Moolekamp & Melchior 2018](https://arxiv.org/abs/1708.09066) and [Melchior et al. 2018](https://arxiv.org/abs/1802.10157).\n",
    "\n",
    "### Basic Concepts and Structure\n",
    "\n",
    "*scarlet* is designed to separate sources in astrophysical images by assuming that each scene can be thought of as a collection of multiple [Component](component.ipynb#scarlet.component.Component) objects.\n",
    "Each component has a center, morphology (shape) and spectrum (or SED) with a set of [Constraint](constraint.ipynb#scarlet.constraint.Constraint)s they need to obey.\n",
    "Components can be grouped into [Source](source.ipynb#scarlet.source.Source), e.g. for bulge-disk models, that can enforce additional constraints on the centers, SEDs, and morphologies of all components. It's a base class, from which specialized classes can be derived to adjust to the sitation at hand. \n",
    "This customization can comprise the number of components, their initialization, and the constraints they need to obey, or all of those.\n",
    "\n",
    "The [Blend](blend.ipynb#scarlet.blend.Blend) class contains all of the information about the scene, i.e. the collection of components, as well as routines for fitting the joint model to data.\n",
    "It implements the minimization algorithm described in [Moolekamp & Melchior 2018](https://arxiv.org/abs/1708.09066).\n",
    "Below is a very brief summary of the method:\n",
    "\n",
    "The deblending algorithm forms a model of the scene\n",
    "\n",
    "$$\\mathsf{M}= \\sum_{k=1}^K \\mathsf{A}_k^T \\times \\mathsf{S}_k = \\mathsf{A}\\mathsf{S}, $$\n",
    "\n",
    "where $\\mathsf{A}_k \\in \\mathbb{R}^B$ is the normalized SED and $\\mathsf{S}_k \\in \\mathbb{R}^N$ is the morphology of a single component in the model with $B$ bands and $N$ pixels in each band.\n",
    "It is important to note that this matrix factorization implies that SEDs and morphologies are independent, e.g. the SED of a component does not change over the region covered by its morphology.\n",
    "\n",
    "The scene is fit by minimizing the likelihood of the model, namely minimizing\n",
    "\n",
    "$$f(\\mathsf{A},\\mathsf{S}) = \\frac{1}{2} || \\mathsf{Y}-\\mathsf{A}\\mathsf{S} ||_2^2, $$\n",
    "\n",
    "where $\\mathsf{Y}$ is an image cube and $||.||_2$ is the element-wise $L_2$ (Frobenius) norm.\n",
    "\n",
    "Each component $j$ can have $M_j$ different constraint functions $g_{ji}$, equivalent to minimizing\n",
    "\n",
    "$$f(\\mathsf{A}, \\mathsf{S}) + \\sum_{j=1}^K \\sum_{i=1}^{M_j} g^A_{ji} \\left(\\mathsf{A}_{ji} \\right) + g^S_{ji} \\left(\\mathsf{S}_{ji} \\right)$$\n",
    "\n",
    "Those constraints are applied to each source in the form of proximal operators, a handy mathematical approach for imposing non-smooth constraints that (if properly formulated) are guaranteed to converge; the curious reader will find more details in [Parikh & Boyd 2014](http://www.web.stanford.edu/~boyd/papers/pdf/prox_algs.pdf) and [Combettes & Pesquet 2011](https://link.springer.com/chapter/10.1007/978-1-4419-9569-8_10).\n",
    "In short, proximal operators map an input vector to the nearest vector that satisfied the respective constraint.\n",
    "Many constraints/penalty functions have analytic proximal operators. \n",
    "\n",
    "*scarlet* allows for two different kinds of constraints: proximal operators in the direct domain (that is directly on the SEDs $\\mathsf{A}_k$ and morphologies $\\mathsf{S}_k$) or in the transformed domain, i.e. after SEDs and morphologies are transformed by a linear operator $\\mathsf{L}$ that is specified by the user. Any linear operator is allowed (it does not have to be invertible), examples are finite differences or basis transforms. The main reason for working in the transformed domain is that it can be much easier to express the constraint, for instance that a particular solution have only one Fourier coefficient.\n",
    "\n",
    "Proximal operators for the direct and transformed domain behave differently. The former can be thought of as *strictly* obeyed at every iteration, while the latter ones will converge to a solution that obeys the constraint eventually. \n",
    "To see this it is useful to understand how $\\mathsf{A}$ and $\\mathsf{S}$ are updated:\n",
    "\n",
    "$$ x^{\\textrm{it}+1} \\leftarrow \\textrm{prox}_{\\lambda f} \\left( x^{\\textrm{it}} - \\frac{\\lambda}{\\rho} \\mathsf{L}^T \\left( \\mathsf{L} x^{\\textrm{it}}-z^{\\textrm{it}} + u^{\\textrm{it}} \\right) \\right)$$\n",
    "\n",
    "$$z^{\\textrm{it}+1} \\leftarrow \\textrm{prox}_{\\rho g} \\left( \\mathsf{L} x^{\\textrm{it}+1} + u^{\\textrm{it}} \\right)$$\n",
    "\n",
    "$$u^{\\textrm{it}+1} \\leftarrow u^{\\textrm{it}} + \\mathsf{L} x^{\\textrm{it}+1} - z^{\\textrm{it}+1}$$\n",
    "\n",
    "where $x^{\\textrm{it}}$ denotes either $\\mathsf{A}_k$ or $\\mathsf{S}_k$ in the current iteration, and $\\textrm{prox}_f$ performs (at least) a step in the direction of the negative gradient of the log-likelihood. $\\textrm{prox}_g$ is the proximal operator in the transformed domain as it acts on $\\mathsf{L} x$ instead of $x$.\n",
    "If additional constraints in the direct domain are present, they will be subsumed in $\\textrm{prox}_f$, thus making sure that they are satisfied in every iteration."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. note::\n",
    "\n",
    "    `Blend` operates on a list of `Component`s, but the typical interface to the user is the `Source` class:\n",
    "    It is the prime responsibility of the user to choose or devise the appropriate sources (including constraints) that are useful to model a given scene.\n",
    "    Changes to the functionality of `Blend` are normally not needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources\n",
    "\n",
    "The [Component](component.ipynb#scarlet.component.Component) class requires an initial guess for the SED and morphology of each source. While *scarlet* can run on a collection of components, most users want to construct a list of [Source](source.ipynb#scarlet.source.Source)s, which are itself a list of components that are forced to be co-centered.\n",
    "The advantage of using [Source](source.ipynb#scarlet.source.Source) or a class derived from it is that it provides a higher-level interface to initialize the component given the actual data at hand:\n",
    "* [PointSource](source.ipynb#scarlet.source.PointSource)\n",
    "* [ExtendedSource](source.ipynb#scarlet.source.ExtendedSource)\n",
    "* [MultiComponentSource](source.ipynb#scarlet.source.MultiComponentSource).\n",
    "\n",
    "Users with more specific needs can create [custom sources](#Custom-Sources).\n",
    "\n",
    "### Object Detection\n",
    "\n",
    "Before we start, we need to load an example image (here an image cube with 5 bands) *and* a detection catalog.\n",
    "If such a catalog is not available, packages like [SEP](http://sep.readthedocs.io/) or [photutils](https://photutils.readthedocs.io/en/stable/) will happily generate one.\n",
    "Instead, we will simply load the truth catalog of the simulation.\n",
    "While not fundamentally needed, *scarlet* works best if the background noise levels are known as well, so we'll also set it to the truth value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# use a better colormap and don't interpolate the pixels\n",
    "matplotlib.rc('image', cmap='inferno')\n",
    "matplotlib.rc('image', interpolation='none')\n",
    "\n",
    "import numpy as np\n",
    "import scarlet\n",
    "\n",
    "# Load the sample images\n",
    "data = np.load(\"../data/test_sim/data.npz\")\n",
    "images = data[\"images\"]\n",
    "\n",
    "# Load the thruth detection catalog\n",
    "from astropy.table import Table as ApTable\n",
    "catalog = ApTable.read(\"../data/test_sim/true_catalog.fits\")\n",
    "bg_rms = np.array([20]*len(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization\n",
    "\n",
    "Fundamentally, a [Component](source.ipynb#scarlet.source.Source) needs to hold a SED and a morphology.\n",
    "A simple one-pixel example with a SED taken from the center of the image can be set up like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "B, Ny, Nx = images.shape\n",
    "center = (Ny//2, Nx//2)\n",
    "# Get the SED at the location of the central pixel\n",
    "sed = scarlet.source.get_pixel_sed(images, center)\n",
    "# Set the morphology such that only the central pixel has any intensity\n",
    "morph = np.zeros((Ny, Nx))\n",
    "morph[center] = 1\n",
    "comp = scarlet.Component(sed, morph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Components will typically have a `center` (position) argument, but it's not required as some source types are not (well) localized.\n",
    "\n",
    "The location of the center can be re-adjusted to improve localization and to better satisfy constraints like symmetry and monotonicity, which are evaluated with respect to the center.\n",
    "This is done by calculating the dipole of the residuals when shifting the model by `shift_center`, typically a fraction of a pixel.\n",
    "If there is a good reason to believe that the initial positions are correct (such as in simulations), one can set `shift_center=0`.\n",
    "\n",
    "In general, most components only cover a small region of the full image, it is therefore more computationally efficient to initialize them in the smallest possible frame (or bounding box).\n",
    "When the entire blend is fit, the size of this frame is recalculated if `fix_frame` is `False` (the default value).\n",
    "\n",
    "One can also prevent the fitting procedure to prevent changes to SED or morphology by setting `fix_sed` or `fix_morph` to `True` (default is `False`).\n",
    "\n",
    "The [Source](source.ipynb#scarlet.source.Source) base class is only a wrapper around one or several [Component](component.ipynb#scarlet.component.Component). It can be initalized by constrcting a componentn, but it is more common to initialize a source using an inherited class.\n",
    "For example, [PointSource](source.ipynb#scarlet.source.PointSource) creates a new source given a `center` position using the SED of the pixel at that location in each band with only that single pixel turned on in the morphology, which is a decent starting configuration for stars.\n",
    "A more generally useful class is [ExtendedSource](source.ipynb#scarlet.source.ExtendedSource), which initializes a source with a symmetric and monotonic model around the `center` location, using the mean SED over that footprint.\n",
    "If an extended source is better described by multiple components, [MultiComponentSource](source.ipynb#scarlet.source.MultiComponentSource) layers several of them with on top of each other, with the outermost one being indentical to the one used by [ExtendedSource](source.ipynb#scarlet.source.ExtendedSource).\n",
    "\n",
    "For example, to create a list of extendend sources for every source in the input catalog:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sources = [scarlet.source.ExtendedSource((src['y'],src['x']), images, bg_rms) for src in catalog]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that [ExtendedSource](source.ipynb#scarlet.source.ExtendedSource) has a few additional arguments compared to the [Source](source.ipynb#scarlet.source.Source) base class.\n",
    "It requires `img` to determine the initial SED and morphology and the background level `bg_rms` to determine to size of the frame (or bounding box)."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. warning::\n",
    "\n",
    "    Note in the code above that coordinates in *scarlet* use the traditional C/numpy notation (y,x) as opposed to the mathematical (x,y) ordering. A common error when first starting out with *scarlet* is to mix the order of x and y in your catalog or source list."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. note::\n",
    "\n",
    "    It is possible to fix the position of a single component while recentering other components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constraints\n",
    "\n",
    "### Introduction\n",
    "*scarlet* is implemented in a modular and flexible way that allows users to implement custom constraints tailored to the situations at hand.\n",
    "\n",
    "When specifying a constraint the user can choose what quantity is affected, and how. The [Constraint](constraint.ipynb#scarlet.constraint.Constraint) base class holds these members:\n",
    "```\n",
    "prox_sed\n",
    "prox_morph\n",
    "prox_g_sed\n",
    "L_sed\n",
    "prox_g_morph\n",
    "L_morph\n",
    "source\n",
    "```\n",
    "The methods are generators that return a proximal operator function given the shape of the container it need to operate on; this complication allows to reshape e.g. a component morphology and have the constraint adjust transparently. Here's an example of the default constraint [MinimalConstraint](constraint.ipynb#scarlet.constraint.MinimalConstraint), which requires the SED to have non-negative elements and the morphology to be non-negative and normalized so that the center pixel value is `1`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scarlet.constraint as sc\n",
    "constraint = sc.MinimalConstraint()\n",
    "shape = (20,20)\n",
    "\n",
    "import inspect\n",
    "inspect.signature(constraint.prox_morph)\n",
    "from inspect import signature\n",
    "print (\"Method:\", constraint.prox_morph)\n",
    "print (\"Signature:\", signature(constraint.prox_morph))\n",
    "print (\"Returns:\", constraint.prox_morph(shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operators are called `prox_<sed/morph>` in the direct domain and `prox_g_<sed/morph>` in the transformed domain, for reasons that should be clear from the equations [above](#Basic-Concepts-and-Structure).\n",
    "Any of the members above can return `None`, which implies that the respective constraints are mute.\n",
    "If `L_<sed/morph> is None` and `prox_g_<sed/morph>` is set, we assume the the transformation matrix $\\mathsf{L}$ is the identity.\n",
    "\n",
    "Multiple constraints can be combined in a list or tuple. This allows for arbitrary combinations of constraints.\n",
    "For example, we can combine [MinimalConstraint](constraint.ipynb#scarlet.constraint.MinimalConstraint) with an [L0Constraint](constraint.ipynb#scarlet.constraint.L0Constraint) using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "constraint = (sc.MinimalConstraint(), sc.L0Constraint(0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A related constraint is the [SimpleConstraint](constraint.ipynb#scarlet.constraint.SimpleConstraint), which additionally ensures that the source has a very small amount of flux, which prevents sources that are not initially given any flux from causing the optimization to diverge.\n",
    "\n",
    "Both the [MinimalConstraint](constraint.ipynb#scarlet.constraint.MinimalConstraint) and [SimpleConstraint](constraint.ipynb#scarlet.constraint.SimpleConstraint) take an optional `normalization` parameter, which allows the user to decide whether to normalize the `A` or `S` matrix. See [Normalization](#Normalization) for more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Symmetry\n",
    "\n",
    "Demanding that astrophysical sources are symmetric reduces the number of effective degrees of freedom of the model, and most galaxies are *largely* symmetric.\n",
    "The idea has been used successfully in the SDSS deblender and also in our tests on substantially deeper HSC images.\n",
    "\n",
    "Symmetry can be enforced in either the direct or transformed domain, where the former has the ability to specify how strictly symmetry is enforced (for example grand design spirals, irregular galaxies, and jets are not perfectly symmetric and it can be useful to use a softer penalty).\n",
    "\n",
    "#### Direct Symmetry\n",
    "\n",
    "Direct symmetry imposes the [prox_soft_symmetry](operators.ipynb#scarlet.operators.prox_soft_symmetry) projection operator:\n",
    "\n",
    "$$ \\textrm{prox}_\\textrm{sym} = \\frac{\\sigma}{2} \\left( S_k + S_k^\\dagger \\right) + \\left(1-\\sigma \\right) S_k $$\n",
    "\n",
    "where $S_k$ is the flattened morphology matrix for a single source and $S_k^\\dagger$ is it's symmetric version.\n",
    "So the parameter $\\sigma \\in [0,1]$ determines the minimum symmetry required, where $\\sigma=0$ imposes no symmetry constraint at all while $\\sigma=1$ enforces perfect symmetry.\n",
    "\n",
    "We can combine a direct symmetry constraint with the minimal constraint using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "constraint = (sc.MinimalConstraint(), sc.DirectSymmetryConstraint(sigma=0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Symmetry in the Transformed Domain\n",
    "\n",
    "In the transformed domain symmetry is implemented using a linear matrix $\\mathsf{L}=$[getSymmetryOp](transformations.ipynb#scarlet.transformations.getSymmetryOp), which encodes the difference between each pixel and it's symmetric partner, and the proximal operator `proxmin.operators.prox_zero` forces the transformed variable to be zero.\n",
    "As stated in the previous subsection, this constraint is not strictly met in any given iteration but will converge over time to a solution with a symmetric morphology.\n",
    "\n",
    "We can combine this constraint with the minimal `constraint` using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "constraint = (sc.MinimalConstraint(), sc.SymmetryConstraint())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monotonicity\n",
    "\n",
    "Another useful constraint from the SDSS-HSC deblender is the approximation that most astrophysical objects are monotonically decreasing from the peak.\n",
    "In detail this assumption is violated e.g. in spiral galxies, especially tightly wound ones.\n",
    "But if we think of spirals as a single source made up of multiple components, each monotonically decreasing from it's peak with a single SED, we can build a model that is well representative of even morphologically complex galaxies.\n",
    "This point of view has the added benefit that regions that are not monotonically decreasing in a galaxy are likely different stellar populations with (potentially) different SED's and should be treated as separate components anyway.\n",
    "\n",
    "Monotonicity in *scarlet* is implemented in the direct and transformed domain, so we will look at each use to see their differences.\n",
    "The easier one to understand is in the transformed domain: the [MonotonicityConstraint](constraint.ipynb#scarlet.constraint.MonotonicityConstraint) class builds a [getRadialMonotonicOp](transformation.ipynb#scarlet.transformation.getRadialMonotonicOp) linear operator that takes the differences between the flux in the reference pixels and the flux in the current pixel.\n",
    "The transformed morphology vector is then passed on to the `proxmin.operators.prox_plus` proximal operator to project it onto the subspace where all values are non-negative.\n",
    "If `use_nearest` is `True`, only a single reference pixel is used: the nearest one in the direction to the peak.\n",
    "Otherwise a weighted average of all pixels closer to the peak than the current pixel is used to allow for a smoother monotonic solution.\n",
    "\n",
    "| ![](images/nearest_ref.png) | ![](images/weighted_ref.png) |\n",
    "|:---------------------------:|:----------------------------:|\n",
    "| Nearest Neighbor            | Weighted Reference           |\n",
    "\n",
    "\n",
    "In the following example, for simplicity we use the [PointSource](source.ipynb#scarlet.source.PointSource) class to create a source with a simple initial SED and morphology, but add both a [SymmetryConstraint](constraint.ipynb#scarlet.constraint.SymmetryConstraint) and a [MonotonicityConstraint](constraint.ipynb#scarlet.constraint.MonotonicityConstraint)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Initialize a constraint that is used for all of the sources\n",
    "constraints = (\n",
    "    sc.SimpleConstraint(), # sed sum to unity, all elements of SED and morph are non-negative\n",
    "    sc.MonotonicityConstraint(use_nearest=False), # prox_g monotonicity\n",
    "    sc.DirectSymmetryConstraint() # prox_f perfect symmetry\n",
    ")\n",
    "\n",
    "# Initialize the Sources\n",
    "sources = [scarlet.source.PointSource(\n",
    "    (src['y'],src['x']), # center coordinates in `images`\n",
    "    images, # data cube (bands, Ny, Nx)\n",
    "    (25,25), # initial shape of the bounding box\n",
    "    constraints=constraints,\n",
    "    fix_frame=True # There is a breakage in resizing using the BSDMM algorithm, so we prvent the code from resizing\n",
    ") for src in catalog]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. warning::\n",
    "\n",
    "    When creating a list of sources that all use the same constraint, don't forget to use the `copy` method of the `Constraint` class. Some constraints contain parameters specific to the an individual source and are initialized later, so naively using `constraints=constraint` in the `PointSource` initialization above would result in a single `constraint` that is shared by all of the sources and will likely cause the code to crash, or at best give unexpected results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create a blended scene with all of the sources, and add a helper method to display the model nicely.\n",
    "We'll discuss the [Blend](blend.ipynb#scarlet.blend.Blend) class later, but for now we just use it to run a few iterations to see the monotonicity constraint in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import scarlet.display\n",
    "\n",
    "# Display the sources\n",
    "def display_sources(sources, norm=None, subset=None, combine=False, show_sed=True):\n",
    "    \"\"\"Display the data and model for all sources in a blend\n",
    "    \n",
    "    This convenience function is used to display all (or a subset) of\n",
    "    the sources and (optionally) their SED's.\n",
    "    \"\"\"\n",
    "    if subset is None:\n",
    "        # Show all sources in the blend\n",
    "        subset = range(len(sources))\n",
    "    for m in subset:\n",
    "        # Load the model for the source\n",
    "        src = sources[m]\n",
    "        model = [comp.get_model() for comp in src]\n",
    "        \n",
    "        # Select the image patch the overlaps with the source and convert it to an RGB image\n",
    "        img_rgb = scarlet.display.img_to_rgb(images[src[0].bb], filter_indices=[3,2,1], norm=norm)\n",
    "\n",
    "        # Build a model for each component in the model\n",
    "        rgb = []\n",
    "        for _model in model:\n",
    "            # Convert the model to an RGB image\n",
    "            _rgb = scarlet.display.img_to_rgb(_model, filter_indices=[3,2,1], norm=norm)\n",
    "            rgb.append(_rgb)\n",
    "\n",
    "        # Display the image and model\n",
    "        figsize = [6,3]\n",
    "        columns = 2\n",
    "        # Calculate the number of columns needed and shape of the figure\n",
    "        if show_sed:\n",
    "            figsize[0] += 3\n",
    "            columns += 1\n",
    "        if not combine:\n",
    "            figsize[0] += 3*(len(model)-1)\n",
    "            columns += len(model)-1\n",
    "        # Build the figure\n",
    "        fig = plt.figure(figsize=figsize)\n",
    "        ax = [fig.add_subplot(1,columns,n+1) for n in range(columns)]\n",
    "        ax[0].imshow(img_rgb)\n",
    "        ax[0].set_title(\"Data: Source {0}\".format(m))\n",
    "        for n, _rgb in enumerate(rgb):\n",
    "            ax[n+1].imshow(_rgb)\n",
    "            if combine:\n",
    "                ax[n+1].set_title(\"Initial Model\")\n",
    "            else:\n",
    "                ax[n+1].set_title(\"Component {0}\".format(n))\n",
    "        if show_sed:\n",
    "            for comp in src:\n",
    "                ax[-1].plot(comp.sed)\n",
    "            ax[-1].set_title(\"SED\")\n",
    "            ax[-1].set_xlabel(\"Band\")\n",
    "            ax[-1].set_ylabel(\"Intensity\")\n",
    "        # Mark the current source in the image\n",
    "        y,x = src[0].center\n",
    "        ax[0].plot(x-src[0].bb[2].start, y-src[0].bb[1].start, 'wx', mew=2)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "blend = scarlet.Blend(sources).set_data(images, bg_rms=bg_rms)\n",
    "blend.fit(50)\n",
    "\n",
    "# Set the arcsinh color scaling object\n",
    "asinh = scarlet.display.Asinh(img=images, Q=50)\n",
    "\n",
    "# For simplicity only show the first 3 peaks\n",
    "display_sources(sources, subset=[0,1,2], norm=asinh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While sources 1 and 2 look ok, we see that source 0 is clearly not monotonically decreasing from the center; if you look closely, neither is source 1.\n",
    "\n",
    "Now we'll use the direct monotonicity, which forces all of the pixels to be monotonically decreasing by starting at the center pixel and working radially outward to enforce monotonicity. This also comes in a weighted and nearest neighbor version, so for consistency we use the nearest neighbor monototonicity again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a constraint that is used for all of the sources\n",
    "constraint = (\n",
    "    sc.SimpleConstraint(), # sed sum to unity, all elements of SED and morph are non-negative\n",
    "    sc.DirectMonotonicityConstraint(use_nearest=False), # prox_f monotonicity\n",
    "    sc.DirectSymmetryConstraint() # prox_f perfect symmetry\n",
    ")\n",
    "\n",
    "# Initialize the Sources\n",
    "sources = [scarlet.source.PointSource(\n",
    "    (src['y'],src['x']), # center coordinates in `images`\n",
    "    images, # data cube (bands, Ny, Nx)\n",
    "    (15,15), # initial shape of the bounding box\n",
    "    constraints=constraint\n",
    ") for src in catalog]\n",
    "\n",
    "# Create the blend and display the sources\n",
    "blend = scarlet.Blend(sources).set_data(images, bg_rms=bg_rms)\n",
    "blend.fit(50)\n",
    "display_sources(sources, subset=[0,1,2], norm=asinh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we see significant improvement using the direct monotonicity, even though (for reasons beyond the scope of this document) it is not an exact proximal operator.\n",
    "We have an `exact` version of the direct monotonicity, but it is too slow to be used in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization\n",
    "\n",
    "The product of two matrices, in this case $AS$, has an infinite number of equivalent solutions if both $A$ and $S$ are allowed to vary freely. Typically this degeneracy is broken by normalizing either the $A$ or $S$ matrix in some way. In _scarlet_ this normalization is left up to the user by setting the `normalization` parameter of a source to a [Normalization](constraint.ipynb#scarlet.constraint.Normalization) member. \n",
    "\n",
    "The three different normalization methods are\n",
    "\n",
    "* `Normalization.A`\n",
    "* `Normalization.S`\n",
    "* `Normalization.Smax`\n",
    "\n",
    "`Normalization.A` normalizes the $A$ matrix so that it sums to unity for each source, essentially making $A$ a  normalized SED while the $S$ matrix contains both shape and intensity information. This has the advantage that the SED, which converges much faster, is stable for the majority of the iterations. The disadvantage is that overlapping sources that are roughly the same color but have very different intensities (which is common in galaxy clusters, for example) can be difficult to separate with this normalization.\n",
    "\n",
    "`Normalization.S` normalizes the $S$ matrix so that it sums to unity for each source, so that $A$ now contains both color and intensity information. The advantage to this method is that two sources with very similar colors are easier to distinguish if they have very different intensities. The other big advantage of this normalization is that true point sources can be fit much more easily and efficiently by fixing the morphology and normalizing $S$, meaning the intensity of the central pixel equals 1 for all iterations and only the colors and intensities in $A$ are modified.\n",
    "\n",
    "The main disadvantage of this method is that using `Normalization.S` for an [ExtendedSource](#scarlet.source.ExtendedSource) causes fluctuations in the values of the outer pixels during fitting to affect the overall global normalization of $S$ for each source, meaning a peak pixel that is relatively well constrained will not be fixed if a large number of pixels on the outer edges of the star change value (which can happen while fitting regions with low signal to noise, especially if they overlap with another source).\n",
    "\n",
    "To limit this affect we provide the `Normalization.Smax` normalization, which normalizes $S$ so that the peak is always set to a value of 1. This should make the values near the peak more robust, but in practice `Normalization.S` is often the fastest option to converge, with better residuals than the other two normalization methods. However, until this is fully tested, the default normalization is `Normalization.A` to keep backwards compatibility with older versions of _scarlet_.\n",
    "\n",
    "See [Point Source Tutorial](tutorials/point_source.ipynb) for more on modeling point sources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Sources\n",
    "\n",
    "Many users may require specialized features that are not implemented in the [Source](source.ipynb#scarlet.source.Source) classes available in *scarlet*, but the codebase is written so that they can easily be extended. For demonstration purposes, we construct a simplistic two-component bulge-disk model below, using the existing code for [ExtendedSource](#scarlet.source.ExtendedSource) and [PointSource](#scarlet.source.PointSource):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BulgeDiskSource(scarlet.ExtendedSource):\n",
    "    \"\"\"A galactic source with two components\n",
    "    \"\"\"\n",
    "    def __init__(self, center, img, bg_rms, constraints=None, psf=None, symmetric=True, monotonic=True,\n",
    "                 thresh=1., config=None, fix_sed=False, fix_morph=False, fix_frame=False, shift_center=0.2, normalization=sc.Normalization.A):\n",
    "        \n",
    "        # initialize the parent ExtendedSource\n",
    "        super(BulgeDiskSource, self).__init__(center, img, bg_rms, constraints=constraints, psf=psf,\n",
    "                                              symmetric=symmetric, monotonic=monotonic, thresh=thresh, config=config,\n",
    "                                              fix_sed=fix_sed, fix_morph=fix_morph, fix_frame=fix_frame, \n",
    "                                              shift_center=shift_center, normalization=normalization)\n",
    "        \n",
    "        # construct a co-centric point source\n",
    "        ps = scarlet.PointSource(center, img, psf=psf, constraints=constraints, config=config,\n",
    "                                 fix_sed=fix_sed, fix_morph=fix_morph, fix_frame=fix_frame, shift_center=shift_center, normalization=normalization)\n",
    "        \n",
    "        # add point source component to ExtendedSource\n",
    "        self += ps[0]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. warning::\n",
    "\n",
    "    When creating a class inherited from `Source`, don't forget to initialize the `Source` base class.\n",
    "    `Source.__init__` performs the initialization and configuration of parameters necessary for accessing a sources SED and morphology and projecting them properly onto the scene."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create a list of sources with two components, initialized using the `BulgeDiskSource` class above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_sources = [BulgeDiskSource((src[\"y\"], src[\"x\"]), images, bg_rms) for src in catalog]\n",
    "display_sources(bd_sources, subset=[0,1,2], norm=asinh)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. note::\n",
    "\n",
    "    The model of source/components do not exactly correspond to the specified component morphologies: they are translated to the position in the scence and potentially convolved with a PSF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we run *scarlet* for a few iterations we see that the two components have begun to converge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bd_sources = [BulgeDiskSource((src[\"y\"], src[\"x\"]), images, bg_rms) for src in catalog]\n",
    "config = scarlet.Config(accelerated=False) # for more stability\n",
    "blend = scarlet.Blend(bd_sources).set_data(images, bg_rms=bg_rms, config=config)\n",
    "blend.fit(200)\n",
    "display_sources(bd_sources, subset=range(3), norm=asinh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/markdown"
   },
   "source": [
    "Sources have methods to update all of their components at each iteration of `Blend.fit()`:\n",
    "* `update_center()`\n",
    "* `update_sed()`\n",
    "* `update_morph()`\n",
    "\n",
    "By default, `update_center()` forces all components to adopt the flux-weighted center of all constituent components, while the other two functions are inactive. These functions can be modified in derived classes to implement the desired behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blended Scenes\n",
    "\n",
    "The [Blend](blend.ipynb#scarlet.blend.Blend) class contains the entire blended scence as well as the functions to fit to data. Internally, it organizes the components as a tree that has the same access pattern to its components as [Source](source.ipynb#scarlet.source.Source).\n",
    "\n",
    "### Configuration\n",
    "\n",
    "A number of global configuration options, used by both [Blend](blend.ipynb#scarlet.blend.Blend) and [Source](source.ipynb#scarlet.source.Source) objects, are accessed through the [Config](config.ipynb#scarlet.config.Config) class.\n",
    "See [Configuration](config.ipynb#Configuration-(scarlet.config)) for a detailed description of different configuration options.\n",
    "\n",
    "Most of the properties can be modified by the user on the fly, but changing the `Config.source_sizes` propery should be accomplished by using the [Config.set_source_sizes](config.ipynb#scarlet.config.Config.set_source_sizes) method, which ensures that all of the `source_sizes` are valid (see [Config](config.ipynb#scarlet.config.Config) for more).\n",
    "\n",
    "### Initialization\n",
    "\n",
    "Initializing a new blended scene requires a list of `sources` ([Source](#scarlet.source.Source) objects), an image (`img`) datacube with dimensions (`bands`, `height`, `width`).\n",
    "If a weightmap exists, the user can also pass a `weights` datacube with the same dimensions as `img`.\n",
    "It is also useful to pass a value for the background RMS (`bg_rms`), which is used to adjust the box size needed for each source (see the discussion in [Adjusting Sources](#Adjusting-Sources)).\n",
    "Finally an optional [Config](config.ipynb#scarlet.config.Config) class can be specified, with custom configuration options.\n",
    "\n",
    "For most users, a good place to start is by defining each source as an [ExtendedSource](source.ipynb#scarlet.source.ExtendedSource) and initializing a blend with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = [scarlet.source.ExtendedSource((src['y'],src['x']), images, bg_rms) for src in catalog]\n",
    "blend = scarlet.Blend(sources)\n",
    "blend.set_data(images, bg_rms=bg_rms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates a scene with a collection of sources, each one with a single SED and a morphology that is both monotonic and symmetric (see [Sources](#Sources)), and will use `bg_rms` to minimize the box sizes of each source.\n",
    "\n",
    "To customize the configuration of the [Blend](blend.ipynb#scarlet.blend.Blend), for example using a lower flux threshold for resizing source bounding boxes, a [Blend](blend.ipynb#scarlet.blend.Blend) can be initialized with a new [Config](config.ipynb#scarlet.config.Config)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = scarlet.Config(edge_flux_thresh=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which will resize the box if the model has flux along any edge that us greater than `Config.edge_flux_thresh*bg_rms`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. warning::\n",
    "\n",
    "    A number of internal properties are set when a `Blend` instance is created.\n",
    "    If it is necessary to add or remove sources at a later time, it is best to create a new `Blend` using the new source list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting a Model\n",
    "\n",
    "The [Blend](blend.ipynb#scarlet.blend.Blend) class implement the minimization algorithm described in [Moolekamp & Melchior 2018](https://arxiv.org/abs/1708.09066). See details [above](#Basic-Concepts-and-Structure).\n",
    "\n",
    "The [Blend.fit](blend.ipynb#scarlet.blend.Blend.fit) method will fit the current model and requires two parameters: the maximum number of `steps` (or iterations) used to fit the data and the relative error for convergence (`e_rel`).\n",
    "It stops if one of the following conditions is met:\n",
    "\n",
    "1. The total number of iterations is equal to `steps`\n",
    "\n",
    "1. The model converges (as defined in  [Moolekamp & Melchior 2018](https://arxiv.org/abs/1708.09066)).\n",
    "\n",
    "\n",
    "### Restarting a Fit\n",
    "\n",
    "There may be instances where it is desirable to restart a fit.\n",
    "For example, after a certain number of iterations inspect the result even prior to convergence, or you may have a custom constraint that you want to apply every Nth iteration.\n",
    "In that case you can call `Blend.fit(N1)` and continue with another call to `Blend.fit(N2)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = [scarlet.source.ExtendedSource((src['y'],src['x']), images, bg_rms) for src in catalog]\n",
    "blend = scarlet.Blend(sources).set_data(images, bg_rms=bg_rms)\n",
    "blend.fit(10)\n",
    "print(blend.it)\n",
    "blend.fit(10)\n",
    "print(blend.it)\n",
    "blend.fit(10)\n",
    "print(blend.it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where we see that the last fit the blend converged before reaching 30 iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjusting Components\n",
    "\n",
    "In most blends the number of non-zero pixels is much smaller than the total number of pixels in the image.\n",
    "To save processing time we recommend initializing components with a small number of pixels and allowing the [Blend.fit](blend.ipynb#scarlet.blend.Blend.fit) method to expand the size of the box.\n",
    "This happens automatically for every source with `fix_frame=False` when that source's morphology has any flux above `config.edge_flux_thresh*blend.bg_rms` along the edge of its current bounding box.\n",
    "\n",
    "With the default [symmetry](#Symmetry) and [monotonicity](#Monotonicity) constraints the model is dependent on the accuracy of the center position for each source.\n",
    "The [Blend.recenter_sources](blend.ipynb#scarlet.blend.Blend.recenter_sources) method recenters all sources with `shift_center > 0` simultaneously by calculateing the shifts needed to align the models with the data to null any residual dipoles.\n",
    "\n",
    "Both resizing sources and recentering sources are expensive operations (as resizing requires rebuilding all of the constraint operators and recentering requires building a shifted model) and are thus only performed every `Config.refine_skip` iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing Individual Sources and Components\n",
    "\n",
    "Internally the algorithm operates on components, not sources (where a single [Source](#scarlet.source.Source) might have multiple components), so a [Blend](blend.ipynb#scarlet.blend.Blend) contains a number of access methods and properties to convert from component space to source space.\n",
    "\n",
    "For example, a `blend` created using the `BulgeDisk` class has two components for each source, for a total of 2$\\times$sources components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_sources = [BulgeDiskSource((src[\"y\"], src[\"x\"]), images, bg_rms) for src in catalog]\n",
    "blend = scarlet.Blend(bd_sources).set_data(images, bg_rms=bg_rms)\n",
    "print(\"Number of sources:\", blend.n_nodes)\n",
    "print(\"Number of components:\", blend.n_components)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we iterate through the sources we can find the index of the component in `blend`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 0\n",
    "for m,src in enumerate(blend):\n",
    "    for l,comp in enumerate(src):\n",
    "        test = blend.components[k] is blend[m][l]\n",
    "        print(\"Source {0}, Component {1} has index {2}: {3}\".format(m,l,k,test))\n",
    "        k += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we can use the index of the model component $k$ to find the index of the source, and the index of the component inside that source:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(blend.K): # K is shorthand for blend.n_components\n",
    "    coord = blend.components[k].coord\n",
    "    print(\"Component {0} has indices {1} in blend\".format(k, coord))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Loading and Displaying a Model\n",
    "\n",
    "### Display functions\n",
    "\n",
    "The [display](display.ipynb) module contains a number of convenience methods to convert an image cube into an RGB image array.\n",
    "\n",
    "There are two stock classes used to scale the pixels in the image, [Linear](display.ipynb#scarlet.display.Linear) and [Asinh](display.ipynb#scarlet.display.Asinh), both of which inherit from the `matplotlib.colors.Normalize` class.\n",
    "This inheritance allows them to be used as normalizations in `matplotlib.pyplot.imshow`, including an `inverse` method that makes it possible to add a colorbar.\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = scarlet.display.Linear(img=images)\n",
    "plt.imshow(images[2], norm=norm)\n",
    "plt.colorbar()\n",
    "plt.title(\"Linear Scaling\")\n",
    "plt.show()\n",
    "\n",
    "norm = scarlet.display.Asinh(img=images)\n",
    "plt.imshow(images[2], norm=norm)\n",
    "plt.colorbar()\n",
    "plt.title(\"Asinh Scaling\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [Linear](display.ipynb#scarlet.display.Linear) class is fairly straightforward, allowing the user to (optionally) pass `vmin` and `vmax` parameters to set the range of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = scarlet.display.Linear(vmin=0, vmax=100)\n",
    "plt.imshow(images[2], norm=norm)\n",
    "plt.colorbar()\n",
    "plt.title(\"Linear Scaling\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [Asinh](display.ipynb#scarlet.display.Asinh) scaling is popular because it is linear for small values and logrithmic for larger fluxes, allowing it to display a wide range of intensities clearly.\n",
    "The actual formula used to scale each pixel is\n",
    "\n",
    "$$f(x) = \\frac{1}{Q} \\sinh^{-1} \\left( Q \\frac{x-v_\\textrm{min}}{v_\\textrm{max}-v_\\textrm{min}} \\right)$$\n",
    "\n",
    "where `Q` is a parameter that defines the strech of the scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = scarlet.display.Asinh(img=images, vmin=0, Q=10)\n",
    "plt.imshow(images[2], norm=norm)\n",
    "plt.colorbar()\n",
    "plt.title(\"Asinh Scaling\")\n",
    "plt.show()\n",
    "\n",
    "norm = scarlet.display.Asinh(img=images, vmin=0, Q=100)\n",
    "plt.imshow(images[2], norm=norm)\n",
    "plt.colorbar()\n",
    "plt.title(\"Asinh Scaling\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An image cube can be converted from a (bands, height, width) array into an RGB image array using the [img_to_rgb](display.ipynb#scarlet.display.img_to_rgb) function.\n",
    "This allows the user to specify a normalization (`norm`), `fill_value` (value to use for any masked pixels), and list of indices to map to R, G, B respectively (`filter_indices`).\n",
    "For example the default is to map the first three bands in reverse order to RGB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rgb = scarlet.display.img_to_rgb(images, norm=asinh)\n",
    "plt.imshow(img_rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case the mapping is $r \\rightarrow R$, $g \\rightarrow G$, $u \\rightarrow B$.\n",
    "A more natural mapping (and the one used in most of this document) is $i \\rightarrow R$, $r \\rightarrow G$, $g \\rightarrow B$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rgb = scarlet.display.img_to_rgb(images, filter_indices=[3,2,1], norm=asinh)\n",
    "plt.imshow(img_rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Models from a Blend\n",
    "\n",
    "You can load the models that make up a scene at any time, even if the blend has been initialized but not fit for a single iteration. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the blend but don't fit the model\n",
    "bd_sources = [BulgeDiskSource((src[\"y\"], src[\"x\"]), images, bg_rms) for src in catalog]\n",
    "blend = scarlet.Blend(bd_sources).set_data(images, bg_rms=bg_rms)\n",
    "model = blend.get_model()\n",
    "img_rgb = scarlet.display.img_to_rgb(model, filter_indices=[3,2,1], norm=asinh)\n",
    "plt.imshow(img_rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to load the model for each component individually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = blend.get_model(\n",
    "    combine=False # Don't combine the model for each source together\n",
    ")\n",
    "for model in models:\n",
    "    img_rgb = scarlet.display.img_to_rgb(model, filter_indices=[3,2,1], norm=asinh)\n",
    "    plt.imshow(img_rgb)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Models from a Source\n",
    "\n",
    "It is also possible to access the morphology of a given source directly, which is always centered in its own box:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = bd_sources[0]\n",
    "plt.imshow(src[0].morph)\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(src[1].morph)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that different components of the same source can have different boxes. We can also look at the SED for each source:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m, src in enumerate(blend):\n",
    "    # Only display the SED for the outer components\n",
    "    plt.plot(src[0].sed, label=m)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Useful Source Properties\n",
    "\n",
    "Below are a list of properties that can be accessed for a component. For more information about them, see [Component](component.ipynb#scarlet.component.Component)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp = blend[0][0]\n",
    "print(\"Source shape:\", comp.shape)\n",
    "print(\"Source dimensions:\", (comp.Ny, comp.Nx))\n",
    "print(\"Center:\", comp.center)\n",
    "print(\"Center pixel:\", comp.center_int)\n",
    "print(\"Bounding box of component in the frame of images:\", comp.bb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the image centered on the source, where `comp.bb` is the bounding box to extract the source:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_img = images[comp.bb]\n",
    "img_rgb = scarlet.display.img_to_rgb(_img, filter_indices=[3,2,1], norm=asinh)\n",
    "plt.imshow(img_rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A component can be defined with some fraction of its box outside of the original images.\n",
    "To map a component to the image , it is thus best to use [Component.get_slice_for()](component.ipynb#scarlet.component.Component.get_slice_for), where `comp.morph[comp.get_slice_for(images.shape)]` is the same shape and aligned with `images[comp.bb]`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6,3))\n",
    "ax = [fig.add_subplot(1,2,1+n) for n in range(2)]\n",
    "ax[0].imshow(img_rgb)\n",
    "_img = scarlet.display.img_to_rgb(comp.get_model()[comp.get_slice_for(images.shape)], filter_indices=[3,2,1], norm=asinh)\n",
    "ax[1].imshow(_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This concludes the overview. The user is referred to the [API Documentation](api_docs.rst) for more details about the objects used in *scarlet*."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
