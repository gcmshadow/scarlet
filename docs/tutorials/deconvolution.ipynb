{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deconvolution Tutorial\n",
    "\n",
    "## Introduction\n",
    "\n",
    "There are several problems with the standard initialization performed in the [Quickstart Guide](../0-quickstart.ipynb):\n",
    "\n",
    "1. The models exist in a frame with a narrow model PSF while the the observed scene will have a much wider PSF. So the initial models will be spread out over a larger region, which causes more blending and an increased number of iterations for convergence.\n",
    "\n",
    "1. The initial morphologies for `ExtendedSource`s and `MultibandSource`s are determined using a combined \"detection coadd,\" which weights each observed image with the SED at the center of each source. Due to different seeing in each band, this results in artificial color gradients in the detection coadd that produce a less accurate initial model.\n",
    "\n",
    "One way to solve these problems is to deconvolve the observations into the model frame where the PSF is the same in each band, resulting in more accurate initial morphologies and colors. This is not a trivial task, as deconvolution of a noisy image is an ill-defined operation and numerical divergences dominate the matching kernel when matching a wider PSF to a narrower PSF in Fourier space.\n",
    "\n",
    "To avoid the numerical instability of deconvolution kernels created in k-space we instead use scarlet itself to model the kernel and deconvolve the image. There is a computational cost to this procedure and creating the deconvolution kernel for use with a single blend is not advisable, as the cost to generate it is greater than the time saved. However, there are some situations where the following procedure is quite useful, including deblending a large number of blends from survey data where the PSF is well-behaved. For example, we have experimented with HSC data and found that if we calculate the deconvolution kernel at the center of a 4k$\\times$4k patch, we can use the result to deconvolve _all_ of the blends from the same coadd. This is possible because the deconvolution doesn't have to be exact, we just require it to be better for _initialization_ than the observed images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Packages and setup\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import scarlet\n",
    "import scarlet.display as display\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# use a good colormap and don't interpolate the pixels\n",
    "matplotlib.rc('image', cmap='inferno', interpolation='none', origin='lower')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Display Data\n",
    "\n",
    "We load the same example data set used in the quickstart guide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the sample images\n",
    "data = np.load(\"../../data/hsc_cosmos_35.npz\")\n",
    "images = data[\"images\"]\n",
    "filters = data[\"filters\"]\n",
    "catalog = data[\"catalog\"]\n",
    "weights = 1/data[\"variance\"]\n",
    "# Note that unlike in the quickstart guide,\n",
    "# we set psfs the data[\"psfs\"] image\n",
    "# not a scarlet.PSF object.\n",
    "psfs = data[\"psfs\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the PSF models\n",
    "\n",
    "Unlike the [Quickstart Guide](../0-quickstart.ipynb), we cannot use the pixel integrated model PSF because the [error function](https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.special.erf.html) in scipy used to integrate the gaussian goes to zero too quickly to match an observed PSF. So instead we use a gaussian with a similar $\\sigma=1/\\sqrt{2}$ for our model. We then make this the _observed_ PSF, since this is the seeing that we want to deconvolve our observed images into."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py, px = np.array(psfs.shape[1:])//2\n",
    "model_psf = scarlet.psf.gaussian(py, px, 1/np.sqrt(2), bbox=scarlet.Box(psfs.shape), integrate=False)[0]\n",
    "model_psf = model_psf/model_psf.sum()\n",
    "model_psf = np.array([model_psf]*psfs.shape[0])\n",
    "model_frame = scarlet.Frame(psfs.shape,channels=filters)\n",
    "\n",
    "psf_observation = scarlet.PsfObservation(model_psf, channels=filters).match(psfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matching the PSFs\n",
    "\n",
    "### Algorithm\n",
    "\n",
    "To understand how the matching algorithm works it is useful to understand how convolutions are performed in scarlet. We can define the observed PSF $P$ by convolving the model PSF $M$ with the difference kernel $D$, giving us\n",
    "\n",
    "$P = M * D$,\n",
    "\n",
    "where `*` is the convolution operator. The difference kernel is calculated in k-space using the ratio $\\tilde{P}/\\tilde{D}$, which is well defined as long as $P$ is wider than $M$ in real space. Then the `Observation.render` method is used to convolve the model with $D$ to match it with the observed seeing.\n",
    "\n",
    "For deconvolution we require the opposite, namely\n",
    "\n",
    "$M = P * D$\n",
    "\n",
    "As mentioned in the [Introduction](#Introduction) this is numerically unstable because in k-space $\\tilde{D}/\\tilde{P}$ diverges in the wings as $\\tilde{P}$ is narrower than $\\tilde{D}$. Modeling the deconvolution kernel with scarlet is possible because of the commutivity of the convolution operation, where\n",
    "\n",
    "$M = D * P$.\n",
    "\n",
    "In this case we can define $M$ as the observation we seek to match, make $D$ the model we want to fit, and then convolve the model ($D$) with $P$ in each iteration to match the \"data.\" In this way we can fit the deconvolution kernel needed to deconvolve from the observation seeing to the model frame.\n",
    "\n",
    "## An implementation\n",
    "\n",
    "Choosing the correct parameters for PSF matching is a bit of a black art in itself, another reason why deconvolution should only be done when deblending large datasets and the payoff is greater than the cost. For 41$\\times$41 pixel HSC PSFs we've found the following initialization script to work well, however the configuration for your observations may differ substantially.\n",
    "\n",
    "We introduce the `PSFDiffKernel` class, which acts like a scarlet `Component` used to model the scene, however in this case there is a \"source\" for each band since we want out deconvolution kernels to be mono-chromatic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Parameters used to initial and configure the fit.\n",
    "max_iter = 300\n",
    "e_rel = 1e-5\n",
    "morph_step = 1e-2\n",
    "# We should be able to improve our initial guess if we model the\n",
    "# width of the observed PSF and calculate an analytic solution\n",
    "# for the deconvolution kernel, however for now just using the\n",
    "# observed PSF works well.\n",
    "init_guess = psfs.copy()\n",
    "\n",
    "\n",
    "psf_kernels = [\n",
    "    scarlet.PSFDiffKernel(model_frame, init_guess, band, morph_step)\n",
    "    for band in range(len(filters))\n",
    "]\n",
    "\n",
    "psf_blend = scarlet.Blend(psf_kernels, psf_observation)\n",
    "%time psf_blend.fit(max_iter, e_rel=e_rel)\n",
    "plt.plot(psf_blend.loss, \".-\")\n",
    "plt.title(\"$\\Delta$loss: {:.3e}, e_rel:{:.3e}\".format(psf_blend.loss[-2]-psf_blend.loss[-1], (psf_blend.loss[-2]-psf_blend.loss[-1])/np.abs(psf_blend.loss[-1])))\n",
    "plt.show()\n",
    "\n",
    "for band, src in enumerate(psf_blend.sources):\n",
    "        residual = psfs[band]-psf_observation.render(psf_blend.get_model())[band]\n",
    "        print(\"{}: chi^2={:.3f}, max(abs)={:.3f}\".format(filters[band], np.sum(residual**2), np.max(np.abs(residual))))\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(7, 3))\n",
    "        ax[0].imshow(src.get_model()[band], cmap=\"Greys_r\")\n",
    "        ax[0].set_title(\"{} band kernel\".format(filters[band]))\n",
    "        vmax = np.max(np.abs(residual))\n",
    "        im = ax[1].imshow(residual, vmin=-vmax, vmax=vmax, cmap=\"seismic\")\n",
    "        ax[1].set_title(\"residual\")\n",
    "        plt.colorbar(im, ax=ax[1])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The residual is created by convolving the observed PSF with the deconvolution kernel and comparing it to the model PSF. We see that the kernel isn't perfect and that it tends to overshoot the center of the model PSF, but the result is good enough to improve our initialization. One thing that we've noticed is that if we set our relative error too low then the ringing in the wings of bright objects is too large while running for too long makes the images crisper at the cost of amplifying the noise to the point where it isn't useful for faint (and even moderately faint) sources.\n",
    "\n",
    "We now create the frame for our model, using an analytic PSF, and an observation for the deconvolved image. This is a `DeconvolvedObservation` class, which sets the deconvolution kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the frame for our model\n",
    "model_psf = scarlet.PSF(partial(scarlet.psf.gaussian, sigma=1/np.sqrt(2)), shape=(None, 11, 11))\n",
    "model_frame = scarlet.Frame(\n",
    "            images.shape,\n",
    "            psfs=model_psf,\n",
    "            channels=filters)\n",
    "\n",
    "# This object will perform the deconvolution\n",
    "deconvolved = scarlet.DeconvolvedObservation(\n",
    "            images,\n",
    "            psfs=model_psf,\n",
    "            weights=weights,\n",
    "            channels=filters).match(model_frame, psf_blend.get_model())\n",
    "\n",
    "# These are the observations that we want to model\n",
    "observation = scarlet.Observation(\n",
    "            images,\n",
    "            psfs=scarlet.PSF(psfs),\n",
    "            weights=weights,\n",
    "            channels=filters).match(model_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = deconvolved.images\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15,7))\n",
    "\n",
    "norm = display.AsinhMapping(minimum=np.min(images), stretch=np.max(images)*0.055, Q=10)\n",
    "rgb = display.img_to_rgb(images, norm=norm)\n",
    "ax[0].imshow(rgb)\n",
    "ax[0].set_title(\"Observed\")\n",
    "for center in catalog:\n",
    "    ax[0].plot(center[1], center[0], \"wx\")\n",
    "\n",
    "norm = display.AsinhMapping(minimum=np.min(model), stretch=np.max(model)*0.055, Q=10)\n",
    "rgb = display.img_to_rgb(model, norm=norm)\n",
    "ax[1].imshow(rgb)\n",
    "ax[1].set_title(\"Deconvolved\")\n",
    "for center in catalog:\n",
    "    ax[1].plot(center[1], center[0], \"wx\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case the result isn't great due to the bright star at the center. We could try to fit the model a bit better to supress the ringing but it turns out this is usually unnecessary and not worth the extra computation time.\n",
    "\n",
    "To see how this is useful lets take a look at the detection coadds for the brightest 3 sources with and without deconvolution. These detection coadds are built internally for all extended and multiband sources, but it's a useful exercise to build them separately just to take a look at them. The red x's in the plots below mark the location of the source whose SED was used to make that particular detection coadd:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# We just define a rough estimate of the background RMS needed\n",
    "# for `build_detection_coadd`.\n",
    "bg_rms=np.zeros((len(images),))\n",
    "bg_rms[:] = 1e-3\n",
    "for center in catalog[:4]:\n",
    "    center = (center[1], center[0])\n",
    "    figure, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    # Build the deconvolved coadd\n",
    "    sed = scarlet.source.get_psf_sed(center, deconvolved, model_frame)\n",
    "    detect, bg_cutoff = scarlet.source.build_detection_coadd(sed, bg_rms, deconvolved)\n",
    "    # display\n",
    "    ax[1].imshow(np.log10(detect), cmap=\"Greys_r\")\n",
    "    ax[1].plot(center[1], center[0], \"rx\")\n",
    "    ax[1].set_title(\"deconvolved detection coadd\")\n",
    "    # Build the coadd without deconvolution\n",
    "    sed = scarlet.source.get_psf_sed(center, observation, model_frame)\n",
    "    detect, bg_cutoff = scarlet.source.build_detection_coadd(sed, bg_rms, observation)\n",
    "    #display\n",
    "    ax[0].imshow(np.log10(detect), cmap=\"Greys_r\")\n",
    "    ax[0].plot(center[1], center[0], \"rx\")\n",
    "    ax[0].set_title(\"detection coadd\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the ringing in the PSF doesn't really matter, as it's at the same amplitude as the noise and our initial requirement of monotonicity will trim the model to the inner region that doesn't ring, achieving our goal of making the initial models compact and allowing them to grow if necessary. So next we'll initialize our sources using both the deconvolved and original observations and compare them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the sources without deconvolution\n",
    "sources = []\n",
    "for k,src in enumerate(catalog):\n",
    "    if k == 1:\n",
    "        new_source = scarlet.MultiComponentSource(model_frame, (src['y'], src['x']), observation)\n",
    "    else:\n",
    "        new_source = scarlet.ExtendedSource(model_frame, (src['y'], src['x']), observation)\n",
    "    sources.append(new_source)\n",
    "\n",
    "# Build the convolved sources\n",
    "deconvolved_sources = []\n",
    "for k,src in enumerate(catalog):\n",
    "    if k == 1:\n",
    "        new_source = scarlet.MultiComponentSource(model_frame, (src['y'], src['x']), deconvolved)\n",
    "    else:\n",
    "        new_source = scarlet.ExtendedSource(model_frame, (src['y'], src['x']), deconvolved)\n",
    "    deconvolved_sources.append(new_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = display.AsinhMapping(minimum=np.min(images), stretch=np.max(images)*0.055, Q=10)\n",
    "display.show_sources(sources[:4],\n",
    "                         norm=norm,\n",
    "                         observation=observation,\n",
    "                         show_rendered=True,\n",
    "                         show_observed=True)\n",
    "plt.show()\n",
    "\n",
    "display.show_sources(deconvolved_sources[:3],\n",
    "                         norm=norm,\n",
    "                         observation=observation,\n",
    "                         show_rendered=True,\n",
    "                         show_observed=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the deconvovled initial models use much smaller boxes while still capturing all of the features in the true observations. The better initial guess and smaller boxes will make it much faster to deblend:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the non-deconvolved blend\n",
    "blend = scarlet.Blend(sources, observation)\n",
    "%time blend.fit(200)\n",
    "print(\"scarlet ran for {0} iterations to logL = {1}\".format(len(blend.loss), -blend.loss[-1]))\n",
    "plt.plot(-np.array(blend.loss))\n",
    "plt.title(\"Regular initialization\")\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('log-Likelihood')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the deconvolved blend\n",
    "deconvolved_blend = scarlet.Blend(deconvolved_sources, observation)\n",
    "%time deconvolved_blend.fit(200)\n",
    "print(\"scarlet ran for {0} iterations to logL = {1}\".format(len(deconvolved_blend.loss), -deconvolved_blend.loss[-1]))\n",
    "plt.plot(-np.array(deconvolved_blend.loss))\n",
    "plt.title(\"Deconvolved initialization\")\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('log-Likelihood')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we see that using the deconvolved images for initialization cut our runtime in half for this particular blend (this difference might not be as pronounced in the notebook environment because the default initialization is executed first, heating up the processors before the second blend is run). Looking at the residuals we see that the final models are comparable, so when the same kernel can be used on multiple blends this method proves to be quite useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = display.AsinhMapping(minimum=np.min(images), stretch=np.max(images)*0.055, Q=10)\n",
    "# Display the convolved model\n",
    "scarlet.display.show_scene(blend.sources,\n",
    "                           norm=norm,\n",
    "                           observation=observation,\n",
    "                           show_rendered=True,\n",
    "                           show_observed=True,\n",
    "                           show_residual=True)\n",
    "plt.show()\n",
    "# Display the deconvolved model\n",
    "scarlet.display.show_scene(deconvolved_blend.sources,\n",
    "                           norm=norm,\n",
    "                           observation=observation,\n",
    "                           show_rendered=True,\n",
    "                           show_observed=True,\n",
    "                           show_residual=True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
