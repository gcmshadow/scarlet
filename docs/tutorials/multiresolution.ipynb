{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Resolution Modeling\n",
    "\n",
    "This tutorial shows how to model sources frome images observed with different telescopes. We will use a multiband observation with the Hyper-Sprime Cam (HSC) and a single high-resolution image from the Hubble Space Telescope (HST)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Packages and setup\n",
    "import numpy as np\n",
    "import scarlet\n",
    "import astropy.io.fits as fits\n",
    "from astropy.wcs import WCS\n",
    "from scarlet.display import AsinhMapping\n",
    "from scarlet.initialization import build_initialization_coadd\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# use a better colormap and don't interpolate the pixels\n",
    "matplotlib.rc('image', cmap='gray', interpolation='none', origin='lower')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "We first load the HSC and HST images, channel names, and PSFs. For the images, we need to swap the byte order if necessary because a bug in astropy does not respect the local endianness... We also don't have precomputed weight/variance maps, so we will need to compute them afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the HSC image data\n",
    "obs_hdu = fits.open('../../data/test_resampling/Cut_HSC1.fits')\n",
    "data_hsc = obs_hdu[0].data.byteswap().newbyteorder()\n",
    "wcs_hsc = WCS(obs_hdu[0].header)\n",
    "channels_hsc = ['g','r','i','z','y']\n",
    "\n",
    "# Load the HSC PSF data\n",
    "psf_hsc = fits.open('../../data/test_resampling/PSF_HSC.fits')[0].data\n",
    "Np1, Np2 = psf_hsc[0].shape\n",
    "psf_hsc = scarlet.PSF(psf_hsc)\n",
    "\n",
    "# Load the HST image data\n",
    "hst_hdu = fits.open('../../data/test_resampling/Cut_HST1.fits')\n",
    "data_hst = hst_hdu[0].data\n",
    "wcs_hst = WCS(hst_hdu[0].header)\n",
    "channels_hst = ['F814W']\n",
    "\n",
    "# Load the HST PSF data\n",
    "psf_hst = fits.open('../../data/test_resampling/PSF_HST.fits')[0].data\n",
    "psf_hst = psf_hst[None,:,:]\n",
    "psf_hst = scarlet.PSF(psf_hst)\n",
    "\n",
    "# Scale the HST data\n",
    "n1,n2 = np.shape(data_hst)\n",
    "data_hst = data_hst.reshape(1, n1, n2).byteswap().newbyteorder()\n",
    "\n",
    "r, N1, N2 = data_hsc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Frame and Observations\n",
    "\n",
    "Unlike the single resolution examples, we now have two different instruments with different pixel resolutions, so we need two different observations. Since the HST image is at a much higher resolution, we define our model `Frame` to use the HST PSF and the HST resolution. Because there is no resampling between the model frame and the HST observation, we can use the default `Observation` class for the HST data. The HSC images have lower resolution, so we need to resample the models to this frame, and that's done by `LowResObservation`.\n",
    "\n",
    "Users can specify `Frame`, `Observation` and `LowResObservation` instances by hand and match them as is usually done in single observation fitting. Alternatively, the user can provide a list of observation (no matter what the resolution of each observation is), from which the `from_observations` method will decide how large the model frame has to be and which observation(s) should be a `LowResObservation`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define two observation packages and match to frame\n",
    "obs_hst = scarlet.Observation(data_hst, \n",
    "                              wcs=wcs_hst, \n",
    "                              psfs=psf_hst, \n",
    "                              channels=channels_hst, \n",
    "                              weights=None)\n",
    "\n",
    "obs_hsc = scarlet.Observation(data_hsc, \n",
    "                              wcs=wcs_hsc, \n",
    "                              psfs=psf_hsc, \n",
    "                              channels=channels_hsc, \n",
    "                              weights=None)\n",
    "\n",
    "observations = [obs_hsc, obs_hst]\n",
    "model_frame = scarlet.Frame.from_observations(observations, coverage = 'intersection')\n",
    "obs_hsc, obs_hst = observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we have to create a source catalog for the images. We'll use `sep` for that, but any other detection method will do. Since HST is higher resolution and less affected by blending, we use it for detection but we also run detection on the HSC image to calculate the background RMS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sep\n",
    "\n",
    "def interpolate(data_lr, data_hr):\n",
    "    #Interpolate the low resolution image to high resolution using sinc interpolation\n",
    "    coord_lr0 = (np.arange(data_lr.images.shape[1]), np.arange(data_lr.images.shape[1]))\n",
    "    coord_hr = (np.arange(data_hr.images.shape[1]), np.arange(data_hr.images.shape[1]))\n",
    "    coord_lr = scarlet.resampling.convert_coordinates(coord_lr0, data_lr.frame, data_hr.frame)\n",
    "    \n",
    "    interp = []\n",
    "    for image in data_lr.images:\n",
    "        interp.append(scarlet.interpolation.sinc_interp(image[None, :,:], coord_hr, coord_lr, angle=None)[0].T)\n",
    "    return np.array(interp)\n",
    "        \n",
    "def makeCatalog(data_lr, data_hr, lvl = 3, wave = True):\n",
    "    # Create a catalog of detected source by running SEP on the wavelet transform \n",
    "    # of the sum of the high resolution images and the low resolution images interpolated to the high resolution grid\n",
    "    #Interpolate LR to HR\n",
    "    interp = interpolate(data_lr, data_hr)\n",
    "    # Normalisation \n",
    "    interp = interp/np.sum(interp, axis = (1,2))[:,None, None]\n",
    "    hr_images = data_hr.images/np.sum(data_hr.images, axis = (1,2))[:,None, None]\n",
    "    # Summation to create a detection image\n",
    "    detect_image = np.sum(interp, axis = 0) + np.sum(hr_images, axis = 0)\n",
    "    # Rescaling to HR image flux\n",
    "    detect_image *= np.sum(data_hr.images)\n",
    "    # Wavelet transform\n",
    "    wave_detect = scarlet.Starlet(detect_image, direct = False).coefficients[0]\n",
    "    \n",
    "    if wave:\n",
    "        # Creates detection from the first 3 wavelet levels\n",
    "        detect = wave_detect[:lvl,:,:].sum(axis = 0)\n",
    "    else:\n",
    "        detect = detect_image\n",
    "    # Runs SEP detection\n",
    "    bkg = sep.Background(detect)\n",
    "    catalog = sep.extract(detect, 3, err=bkg.globalrms)\n",
    "    bg_rms = []\n",
    "    for data in [data_lr, data_hr]:\n",
    "        img = data.images\n",
    "        if np.size(img.shape) == 3:\n",
    "            bg_rms.append(np.array([sep.Background(band).globalrms for band in img]))\n",
    "        else:\n",
    "            bg_rms.append(sep.Background(img).globalrms)\n",
    "        \n",
    "    return catalog, bg_rms, detect_image\n",
    "\n",
    "# Making catalog. \n",
    "# With the wavelet option on, only the first 3 wavelet levels are used for detection. Set to 1 for better detection\n",
    "wave = 1\n",
    "lvl = 3\n",
    "catalog_hst, (bg_hsc, bg_hst), detect = makeCatalog(obs_hsc, obs_hst, lvl, wave)\n",
    "\n",
    "# we can now set the empirical noise rms for both observations\n",
    "obs_hsc.weights = np.ones_like(obs_hsc.images) / (bg_hsc**2)[:, None, None]\n",
    "obs_hst.weights = np.ones_like(obs_hst.images) / (bg_hst**2)[:, None, None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can visualize the detections for the multi-band HSC and single-band HST images in their native resolutions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a color mapping for the HSC image\n",
    "norm_hsc = AsinhMapping(minimum=-1, stretch=5, Q=3)\n",
    "norm_hst = AsinhMapping(minimum=-1, stretch=10, Q=5)\n",
    "\n",
    "# Get the source coordinates from the HST catalog\n",
    "pixel_hst = np.stack((catalog_hst['y'], catalog_hst['x']), axis=1)\n",
    "# Convert the HST coordinates to the HSC WCS\n",
    "ra_dec = obs_hst.frame.get_sky_coord(pixel_hst)\n",
    "pixel_hsc = obs_hsc.frame.get_pixel(ra_dec)\n",
    "\n",
    "# Map the HSC image to RGB\n",
    "img_hsc = scarlet.display.img_to_rgb(data_hsc, norm=norm_hsc)\n",
    "# Apply Asinh to the HST data\n",
    "img_hst = scarlet.display.img_to_rgb(data_hst, norm=norm_hsc)\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.subplot(121)\n",
    "plt.imshow(img_hsc)\n",
    "plt.plot(pixel_hsc[:,1],pixel_hsc[:,0], 'or')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(img_hst)\n",
    "plt.plot(pixel_hst[:,1],pixel_hst[:,0], 'xr')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Sources and Blend\n",
    "\n",
    "We expect all sources to be galaxies, so we initialized them as `ExtendedSources`. The initialization can take a list of observations to find initial spectra and morphologies, but we use a custom `coadd` to make use of both data sets for detection.\n",
    "\n",
    "Afterwards, `Blend` will hold a list of all sources and *all* observations to fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a detection coadd\n",
    "coadd, coadd_rms = build_initialization_coadd(observations, filtered_coadd = True)\n",
    "\n",
    "# Source initialisation\n",
    "sources = [\n",
    "    scarlet.ExtendedSource(model_frame, \n",
    "                           sky_coord, \n",
    "                           observations,\n",
    "                           coadd=coadd, \n",
    "                           coadd_rms=coadd_rms)\n",
    "    for sky_coord in ra_dec\n",
    "]\n",
    "\n",
    "blend = scarlet.Blend(sources, observations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Initial guess\n",
    "\n",
    "Let's compare the initial guess in both observation frames. Note that the full model comprises more spectral channels and/or pixels than any individual observation. That's a result of defining "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norms = [norm_hsc, norm_hst]\n",
    "for i in range(len(observations)):\n",
    "    scarlet.display.show_scene(sources, \n",
    "                               norm=norms[i], \n",
    "                               observation=observations[i],\n",
    "                               show_model=False,\n",
    "                               show_rendered=True, \n",
    "                               show_observed=True, \n",
    "                               show_residual=True,\n",
    "                               figsize=(12,4)\n",
    "                              )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time it, logL = blend.fit(20, e_rel = 1.e-7) #Set iterations to 200 for better results\n",
    "print(f\"scarlet ran for {it} iterations to logL = {logL}\")\n",
    "scarlet.display.show_likelihood(blend)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Updated Model\n",
    "\n",
    "We use the same principle to look at the updated model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(observations)):\n",
    "    scarlet.display.show_scene(sources, \n",
    "                               norm=norms[i], \n",
    "                               observation=observations[i],\n",
    "                               show_model=False,\n",
    "                               show_rendered=True, \n",
    "                               show_observed=True, \n",
    "                               show_residual=True,\n",
    "                               figsize=(12,4)\n",
    "                              )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Source Models\n",
    "It can also be useful to view the model for each source. For each source we extract the portion of the image contained in the sources bounding box, the true simulated source flux, and the model of the source, scaled so that all of the images have roughly the same pixel scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(sources)):\n",
    "    print('source number ', k)\n",
    "    for i in range(len(observations)):\n",
    "        scarlet.display.show_sources((sources[k],), \n",
    "                                     norm=norm_hst, \n",
    "                                     observation=observations[i],\n",
    "                                     show_model=False,\n",
    "                                     show_rendered=True, \n",
    "                                     show_observed=True,\n",
    "                                     show_spectrum=False,\n",
    "                                     add_boxes=True,\n",
    "                                     figsize=(8,4)\n",
    "                                    )\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
