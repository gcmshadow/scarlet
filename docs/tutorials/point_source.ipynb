{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Point Source Tutorial\n",
    "\n",
    "This is a quick demonstration of how to model both extended objects and point sources in the same scence. After more testing we hope to replace this with a more robust demonstration of crowded field photometry, using an iterative detection/deblending procedure. In the meantime feel free to create your own algorithm for crowded fields and let us know how it goes on the [DESC Blending](https://lsstc.slack.com/messages/desc-blending) channel on slack.\n",
    "\n",
    "First we load a simulated image where we know the true value of all of the objects. This allows us to know which sources are galaxies and which ones are stars so we can use the appropriate source type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Packages and setup\n",
    "import logging\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import scarlet\n",
    "import scarlet.display\n",
    "from scarlet.constraint import Normalization\n",
    "\n",
    "# For display purposes\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# use a better colormap and don't interpolate the pixels\n",
    "matplotlib.rc('image', cmap='inferno')\n",
    "matplotlib.rc('image', interpolation='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this to point to the location of the data on your system\n",
    "datapath = \"../../data/unmatched_sim\"\n",
    "psfs = np.load(os.path.join(datapath, \"psfs.npz\"))[\"psfs\"]\n",
    "data = np.load(os.path.join(datapath, \"images.npz\"))\n",
    "images = data[\"images\"]\n",
    "filters = data[\"filters\"]\n",
    "\n",
    "# Load the catalog\n",
    "from astropy.table import Table as ApTable\n",
    "catalog = ApTable.read(os.path.join(datapath, \"true_catalog.fits\"))\n",
    "# Only use a single component for each source\n",
    "catalog = catalog[catalog[\"component\"]!=\"disk\"]\n",
    "bg_rms = np.array([20]*len(images))\n",
    "\n",
    "# display psfs\n",
    "pnorm = scarlet.display.Asinh(img=psfs, Q=20)\n",
    "filter_indices = [3,2,1]\n",
    "prgb = scarlet.display.img_to_rgb(psfs, filter_indices=filter_indices, norm=pnorm)\n",
    "plt.imshow(prgb)\n",
    "plt.show()\n",
    "\n",
    "# Use Asinh scaling for the images\n",
    "norm = scarlet.display.Asinh(img=images, Q=20)\n",
    "# Map i,r,g -> RGB\n",
    "# Convert the image to an RGB image\n",
    "img_rgb = scarlet.display.img_to_rgb(images, filter_indices=filter_indices, norm=norm)\n",
    "plt.imshow(img_rgb)\n",
    "for src in catalog:\n",
    "    if src[\"is_star\"]:\n",
    "        plt.plot(src[\"x\"], src[\"y\"], \"rx\", mew=2)\n",
    "    else:\n",
    "        plt.plot(src[\"x\"], src[\"y\"], \"bx\", mew=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the PSFs\n",
    "\n",
    "To avoid artifacts that arise when performing a full deconvolution on exteneded objects, we choose a small \"target\" PSF and calculate the difference kernel to match the PSF in each band to the target. See [Matching PSF's](psf_matching.ipynb) for a more detailed explanation of PSF matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the target PSF to partially deconvolve the image psfs\n",
    "target_psf = scarlet.psf_match.fit_target_psf(psfs, scarlet.psf_match.moffat)\n",
    "# Display the target PSF\n",
    "plt.imshow(target_psf,norm=scarlet.display.Asinh(img=target_psf))\n",
    "plt.show()\n",
    "# Match each PSF to the target PSF\n",
    "diff_kernels, psf_blend = scarlet.psf_match.build_diff_kernels(psfs, target_psf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the sources\n",
    "\n",
    "Here is where we define the sources. In this case we know which ones are stars and which are galaxies, which may or may not be realistic depending on the depth and locations of the images taken. For example, at depths shallower than GAIA it should be possible to flag most of the stars in regions outside the galactic bulge, while in more crowded fields or long exposures a different method might be needed (such as color priors on stars vs galaxies) to determine which sources to model as point sources and which ones to model as extended objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import scarlet.constraint as sc\n",
    "\n",
    "# We turn off acceleration, since it can lead to erratic behavior with certain constraints\n",
    "# More testing will hopefully fix these issues.\n",
    "config = scarlet.config.Config(refine_skip=10, accelerated=False)\n",
    "\n",
    "# This is the constraint to use for a point source, which doesn't\n",
    "# require the more complicated constraints used for extended sources\n",
    "constraints = (sc.SimpleConstraint(normalization=sc.Normalization.S))\n",
    "\n",
    "# Initalize the sources\n",
    "sources = []\n",
    "for src in catalog:\n",
    "    if src[\"is_star\"]:\n",
    "        new_source = scarlet.PointSource(\n",
    "            (src[\"y\"], src[\"x\"]),\n",
    "            images,\n",
    "            fix_morph=True, # This is required to model a point source\n",
    "            constraints = constraints,\n",
    "            psf=psfs, # full PSF convolution from a single point\n",
    "            shape=psfs[0].shape,\n",
    "            normalization=Normalization.S # Use S normalization\n",
    "            #shift_center=0\n",
    "        )\n",
    "    else:\n",
    "        new_source = scarlet.ExtendedSource(\n",
    "            (src[\"y\"], src[\"x\"]),\n",
    "            images,\n",
    "            bg_rms,\n",
    "            psf=diff_kernels, # convolve from target PSF\n",
    "            normalization=sc.Normalization.S, # for consistency with the point sources\n",
    "            #shift_center=0\n",
    "        )\n",
    "    sources.append(new_source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we fix the morphology (`fix_morph=True`) and normalize the $S$ matrix for point sources. This allows us to only set the central pixel and never update it. This is described in more detail in the [User Guide](../user_docs.ipynb#Normalization). You'll also notice that we passed the point sources the full PSF in each band, whereas for the extended sources we pass the difference kernel. This is because a point source is a fully deconvolved representation of the object while extended sources are partially deconvolved. It also means that we have to be careful if we have a scene like this that is a mixture of extended sources and point sources. In order to have a consistent sparse (partially deconvolved) representation of the scene we need to convolve the point sources with the _target PSF_, not the full PSF that matches the image, once deblending has been completed to generate our model.\n",
    "\n",
    "Also notice that we used the same $S$ normalization for both the point sources and extended sources, which allows us to have a consistent definition of $A$ and $S$ for all sources, regardless of their type.\n",
    "\n",
    "## Create the blend and initialize the sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Blend object, which later fits the model\n",
    "blend = scarlet.Blend(sources)\n",
    "blend.set_data(images, bg_rms=bg_rms, config=config)\n",
    "\n",
    "# Display the initial model\n",
    "model = blend.get_model()\n",
    "img_rgb = scarlet.display.img_to_rgb(model, filter_indices=[3,2,1], norm=norm)\n",
    "plt.imshow(img_rgb)\n",
    "for src in catalog:\n",
    "    if src[\"is_star\"]:\n",
    "        plt.plot(src[\"x\"], src[\"y\"], \"rx\", mew=2)\n",
    "    else:\n",
    "        plt.plot(src[\"x\"], src[\"y\"], \"bx\", mew=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our three stars (the red x's) are initialized to match their peak value with the peak of the image while the extended sources are initialized in the usual way.\n",
    "\n",
    "## Fit the model and display the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "blend.fit(200, e_rel=1e-3)\n",
    "print(\"Fit for {0} iterations\".format(blend.it))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,5))\n",
    "ax = [fig.add_subplot(1,3,n+1) for n in range(3)]\n",
    "\n",
    "# Display the data\n",
    "img_rgb = scarlet.display.img_to_rgb(images, filter_indices=filter_indices, norm=norm)\n",
    "ax[0].imshow(img_rgb)\n",
    "ax[0].set_title(\"Data\")\n",
    "for src in catalog:\n",
    "    if src[\"is_star\"]:\n",
    "        ax[0].plot(src[\"x\"], src[\"y\"], \"rx\", mew=2)\n",
    "    else:\n",
    "        ax[0].plot(src[\"x\"], src[\"y\"], \"bx\", mew=2)\n",
    "\n",
    "#Display the model\n",
    "model = blend.get_model()\n",
    "img_rgb = scarlet.display.img_to_rgb(model, filter_indices=[3,2,1], norm=norm)\n",
    "ax[1].imshow(img_rgb)\n",
    "ax[1].set_title(\"Model\")\n",
    "for src in blend.sources:\n",
    "    y, x = src.components[0].center\n",
    "    ax[1].plot(x, y, \"gx\", mew=2)\n",
    "\n",
    "# Display the residual\n",
    "residual = images-model\n",
    "img_rgb = scarlet.display.img_to_rgb(residual, filter_indices=filter_indices)\n",
    "ax[2].imshow(img_rgb)\n",
    "ax[2].set_title(\"Residual\")\n",
    "\n",
    "# Show the plots\n",
    "plt.show()\n",
    "\n",
    "# Show the morphologies\n",
    "for src in blend.sources:\n",
    "    plt.imshow(src.components[0].morph)\n",
    "    plt.show()\n",
    "\n",
    "print(\"Total residual {0}\".format(np.sum(np.abs(residual))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with Extended Sources\n",
    "\n",
    "We now use the same procedure to model all of the sources as extended sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = [\n",
    "    scarlet.source.ExtendedSource(\n",
    "        (src['y'],src['x']),\n",
    "        images,\n",
    "        bg_rms,\n",
    "        psf=diff_kernels,\n",
    "        normalization=sc.Normalization.S\n",
    "    ) for src in catalog\n",
    "]\n",
    "\n",
    "blend = scarlet.Blend(sources)\n",
    "blend.set_data(images, bg_rms=bg_rms, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "blend.fit(200, e_rel=1e-3)\n",
    "print(\"Fit for {0} iterations\".format(blend.it))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,5))\n",
    "ax = [fig.add_subplot(1,3,n+1) for n in range(3)]\n",
    "\n",
    "# Display the data\n",
    "img_rgb = scarlet.display.img_to_rgb(images, filter_indices=filter_indices, norm=norm)\n",
    "ax[0].imshow(img_rgb)\n",
    "ax[0].set_title(\"Data\")\n",
    "for src in catalog:\n",
    "    if src[\"is_star\"]:\n",
    "        ax[0].plot(src[\"x\"], src[\"y\"], \"rx\", mew=2)\n",
    "    else:\n",
    "        ax[0].plot(src[\"x\"], src[\"y\"], \"bx\", mew=2)\n",
    "\n",
    "#Display the model\n",
    "model = blend.get_model()\n",
    "img_rgb = scarlet.display.img_to_rgb(model, filter_indices=[3,2,1], norm=norm)\n",
    "ax[1].imshow(img_rgb)\n",
    "ax[1].set_title(\"Model\")\n",
    "for src in blend.sources:\n",
    "    y, x = src.components[0].center\n",
    "    ax[1].plot(x, y, \"gx\", mew=2)\n",
    "\n",
    "# Display the residual\n",
    "residual = images-model\n",
    "img_rgb = scarlet.display.img_to_rgb(residual, filter_indices=filter_indices)\n",
    "ax[2].imshow(img_rgb)\n",
    "ax[2].set_title(\"Residual\")\n",
    "\n",
    "# Show the plots\n",
    "plt.show()\n",
    "\n",
    "print(\"Total residual {0}\".format(np.sum(np.abs(residual))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for src in blend.sources:\n",
    "    plt.imshow(src.components[0].morph)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we see improvement in computation time, total flux (residual), and galaxy shapes using point sources when we know they can be used."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
